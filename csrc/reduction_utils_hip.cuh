// !!! This is a file automatically generated by hipify!!!
/*
 * Adapted from https://github.com/NVIDIA/FasterTransformer/blob/release/v5.3_tag/src/fastertransformer/kernels/reduce_kernel_utils.cuh
 * Copyright (c) 2023, The vLLM team.
 * Copyright (c) 2020-2023, NVIDIA CORPORATION.  All rights reserved.
 * 
 * Modifications copyright (c) 2024 by SageAttention team.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#if defined(__HIP_PLATFORM_AMD__) || defined(__HIPCC__)
#include <hip/hip_runtime.h>
#else
#include <hip/hip_runtime.h>
#endif

#define FINAL_MASK 0xffffffff

namespace vllm {

template <typename T>
__device__ __forceinline__ T shfl_xor(T val, int laneMask) {
#if defined(__HIP_PLATFORM_AMD__) || defined(__HIPCC__)
  return __shfl_xor(val, laneMask, warpSize);
#else
  return __shfl_xor_sync(FINAL_MASK, val, laneMask, warpSize);
#endif
}

template<typename T>
__inline__ __device__ T warpReduceSum(T val) {
#pragma unroll
  for (int mask = warpSize >> 1; mask > 0; mask >>= 1)
    val += shfl_xor(val, mask);
  return val;
}

template <typename T, int NUM>
__inline__ __device__ T warpReduceSumV2(T* val)
{
#pragma unroll
    for (int i = 0; i < NUM; i++)
    {
#pragma unroll
        for (int mask = warpSize >> 1; mask > 0; mask >>= 1)
            val[i] += shfl_xor(val[i], mask);
    }
    return (T) (0.0f);
}

/* Calculate the sum of all elements in a block */
template<typename T>
__inline__ __device__ T blockReduceSum(T val) {
  // static __shared__ T shared[warpSize];
  __shared__ T shared[warpSize];
  int lane = threadIdx.x & (warpSize - 1);
  int wid = threadIdx.x / warpSize;

  val = warpReduceSum(val);

  if (lane == 0)
    shared[wid] = val;

  __syncthreads();


  const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
  val = (lane < numWarps) ? shared[lane] : (T)(0.0f);
  val = warpReduceSum(val);
  return val;
}

/* Calculate the sum of all elements in a block */
template<typename T>
__inline__ __device__ T blockAllReduceSum(T val) {
  // static __shared__ T shared[warpSize];
  __shared__ T shared[warpSize];
  int lane = threadIdx.x & (warpSize - 1);
  int wid = threadIdx.x / warpSize;

  val = warpReduceSum(val);

  if (lane == 0)
    shared[wid] = val;

  __syncthreads();

  const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
  val = (lane < numWarps) ? shared[lane] : (T)(0.0f);
  val = warpReduceSum(val);
  return val;
}

template <typename T, int NUM>
__inline__ __device__ T blockReduceSumV2(T* val)
{
    // static __shared__ T shared[NUM][warpSize + 1];
    __shared__ T shared[NUM][warpSize + 1];
    int lane = threadIdx.x & (warpSize - 1);
    int wid = threadIdx.x / warpSize;

    warpReduceSumV2<T, NUM>(val);

    if (lane == 0)
    {
#pragma unroll
        for (int i = 0; i < NUM; i++)
        {
            shared[i][wid] = val[i];
        }
    }

    __syncthreads();

    const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
#pragma unroll
    for (int i = 0; i < NUM; i++)
    {
        T tmp = (lane < numWarps) ? shared[i][lane] : T(0);
        val[i] = tmp;
    }
    warpReduceSumV2<T, NUM>(val);
    return (T) 0.0f;
}

template<typename T>
__inline__ __device__ T warpReduceMax(T val)
{
#pragma unroll
     for (int mask = warpSize >> 1; mask > 0; mask >>= 1) {
      T other = shfl_xor(val, mask);
      val = val > other ? val : other;
  }
}
/* Calculate the maximum of all elements in a block */
template<typename T>
__inline__ __device__ T blockReduceMax(T val)
{
    // static __shared__ T shared[warpSize];
    __shared__ T shared[warpSize];
    int                 lane = threadIdx.x & (warpSize - 1);  // in-warp idx
    int                 wid  = threadIdx.x / warpSize;    // warp idx
    val = warpReduceMax(val);  // get maxx in each warp
    if (lane == 0)  // record in-warp maxx by warp Idx
        shared[wid] = val;
    __syncthreads();
    
    const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
    val = (lane < numWarps) ? shared[lane] : -1e20f;
    val = warpReduceMax(val);
    return val;
}

/* Calculate the maximum of all elements in a block */
template <typename T>
__inline__ __device__ T blockAllReduceMax(T val)
{
    // static __shared__ T shared[warpSize];
    __shared__ T shared[warpSize];
    int lane = threadIdx.x & (warpSize - 1); // in-warp idx
    int wid = threadIdx.x / warpSize;    // warp idx

    val = warpReduceMax(val);      // get maxx in each warp

    if (lane == 0)                 // record in-warp maxx by warp Idx
        shared[wid] = val;

    __syncthreads();

    const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
    val = (lane < numWarps) ? shared[lane] : -1e20f;
    val = warpReduceMax(val);

    return val;
}

template<typename T>
__inline__ __device__ T warpReduceMin(T val)
{
#pragma unroll
   for (int mask = warpSize >> 1; mask > 0; mask >>= 1) {
      T other = shfl_xor(val, mask);
      val = val < other ? val : other;
  }
    return val;
}
/* Calculate the minimum of all elements in a block */
template<typename T>
__inline__ __device__ T blockReduceMin(T val)
{
    // static __shared__ T shared[warpSize];
    __shared__ T shared[warpSize];
    int                 lane = threadIdx.x & (warpSize - 1);  // in-warp idx
    int                 wid  = threadIdx.x / warpSize;    // warp idx
    val = warpReduceMin(val);  // get minx in each warp
    if (lane == 0)  // record in-warp minx by warp Idx
        shared[wid] = val;
    __syncthreads();
    
    const int numWarps = (blockDim.x + warpSize - 1) / warpSize;
    val = (lane < numWarps) ? shared[lane] : 1e20f;
    val = warpReduceMin(val);
    return val;
}

} // namespace vllm
